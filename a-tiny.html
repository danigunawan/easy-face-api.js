<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
</head>
<body>
  <h3 align=center>Face-Api.js by <a href="https://github.com/justadudewhohacks">@justadudewhohack</a> 
    simplified for beginners by <a href="https://github.com/hpssjellis/beginner-tensorflowjs-examples-in-javascript">@rocksetta</a></h3>
  
<div id="myDiv01">...</div><br>  
  
<input type=button value=run onclick="{
    run()
}"><br><br>
   
<video onplay="onPlay(this)" id="inputVideo" autoplay muted width="640" height="480" style=" border: 1px solid #ddd;"></video><br>
<canvas id="overlay" width="640" height="480" style="position:relative; top:-487px; border: 1px solid #ddd;" ></canvas><br>
  
</body>

<script>
   // let forwardTimes = []
    
function resizeCanvasAndResults(dimensions, canvas, results) {
  const { width, height } = dimensions instanceof HTMLVideoElement
    ? faceapi.getMediaDimensions(dimensions)
    : dimensions
  canvas.width = width
  canvas.height = height

  // resize detections (and landmarks) in case displayed image is smaller than
  // original size
  return results.map(res => res.forSize(width, height))
}

  
  
function drawDetections(dimensions, canvas, detections) {
  const resizedDetections = resizeCanvasAndResults(dimensions, canvas, detections)
  faceapi.drawDetection(canvas, resizedDetections)
}

  
  
  
function drawLandmarks(dimensions, canvas, results, withBoxes = true) {
  const resizedResults = resizeCanvasAndResults(dimensions, canvas, results)
  if (withBoxes) {
      faceapi.drawDetection(canvas, resizedResults.map(det => det.detection))
  }
  const faceLandmarks = resizedResults.map(det => det.landmarks)
  const drawLandmarksOptions = {
      lineWidth: 2,
      drawLines: true,
      color: 'green'
  }
  faceapi.drawLandmarks(canvas, faceLandmarks, drawLandmarksOptions)
}    
    
    
    
    
    
async function onPlay() {
   const videoEl = document.getElementById('inputVideo')
   const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 128, scoreThreshold : 0.3 }) 

  // const useTinyModel = true
   const faceDetectionTask = faceapi.detectSingleFace(videoEl, options)
   const result = withFaceLandmarks
        ? await faceDetectionTask.withFaceLandmarks(true)
        : await faceDetectionTask

   const drawFunction = withFaceLandmarks
        ? drawLandmarks
        : drawDetections
      
   if (result) {
       drawFunction(videoEl, document.getElementById('overlay'), [result], true)
       
      document.getElementById('myDiv01').innerHTML = '0-of-68x: '+ result._unshiftedLandmarks._positions[0]._x + 
        ', 0-of-68y: '+ result._unshiftedLandmarks._positions[0]._y +'<br>' 
        
   }

    setTimeout(() => onPlay())
}

async function run() {
   await faceapi.loadTinyFaceDetectorModel('https://hpssjellis.github.io/easy-face-api.js/')
   await faceapi.loadFaceLandmarkTinyModel('https://hpssjellis.github.io/easy-face-api.js/')
      
   const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
   const videoEl = document.getElementById('inputVideo')
   videoEl.srcObject = stream
}

</script>
</body>
</html>
