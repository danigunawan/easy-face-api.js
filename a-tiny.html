<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
</head>
<body>
  
  <input type=button value="run" onclick="{ run() }"> 
  <input type=button value="play" onclick="{ onPlay() }">  
  <div id="myDiv01">...</div><br>
  
  <video onplay="onPlay(this)" id="inputVideo" autoplay muted></video>
   <canvas id="overlay" width="640" height="480" style="border: 1px solid #ddd;" title="myFaceCanvas: Zoomed in face"></canvas>  

  </body>

  <script>

  
    let myCanvas = document.getElementById('overlay');
    let myContext = myCanvas.getContext('2d');    
    
    
    
    async function onPlay() {
      
      let withFaceLandmarks = true
      
      const videoEl = document.getElementById('inputVideo')
      const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 128, scoreThreshold : 0.3 }) 
      const result =  await faceapi.detectSingleFace(videoEl, options).withFaceLandmarks
      console.log(result)
      if (result) {
        // faceapi.drawLandmarks(videoEl, myCanvas, [result],  true)
         await faceapi.drawLandmarks(myCanvas, [result],  true)

      }

      setTimeout(() => onPlay())
    }

    async function run() {
      await faceapi.loadTinyFaceDetectorModel('https://hpssjellis.github.io/easy-face-api.js/')
    
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
      const videoEl = document.getElementById('inputVideo')
      videoEl.srcObject = stream
    }

  </script>

</html>
