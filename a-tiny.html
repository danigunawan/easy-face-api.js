<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="js/drawing.js"></script>
</head>
<body>

<input type=button value=run onclick="{
    run()
}">
   
<video onplay="onPlay(this)" id="inputVideo" autoplay muted width="640" height="480" style=" border: 1px solid #ddd;"></video><br>
<canvas id="overlay" width="640" height="480" style="position:relative; top:-487px; border: 1px solid #ddd;" ></canvas><br>
  
<div id="myDiv01">...</div>
</body>

<script>
    let forwardTimes = []
    let withFaceLandmarks = true
    let withBoxes = true

    async function onPlay() {
      const videoEl = document.getElementById('inputVideo')
      const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 128, scoreThreshold : 0.3 }) 

      const useTinyModel = true
      const faceDetectionTask = faceapi.detectSingleFace(videoEl, options)
      const result = withFaceLandmarks
        ? await faceDetectionTask.withFaceLandmarks(useTinyModel)
        : await faceDetectionTask

      const drawFunction = withFaceLandmarks
        ? drawLandmarks
        : drawDetections
      
      if (result) {
        drawFunction(videoEl, document.getElementById('overlay'), [result], withBoxes)
        
     //  console.log('result')
     //  console.log(result)
     //  console.log('faceDetectionTask')
      // console.log(faceDetectionTask)
       
    //  document.getElementById('myDiv01').innerHTML +=result +', '+ faceDetectionTask +'<br>' 
        
      }

      setTimeout(() => onPlay())
    }

    async function run() {
      await faceapi.loadTinyFaceDetectorModel('https://hpssjellis.github.io/easy-face-api.js/')
      await faceapi.loadFaceLandmarkTinyModel('https://hpssjellis.github.io/easy-face-api.js/')
      
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
      const videoEl = document.getElementById('inputVideo')
      videoEl.srcObject = stream

    }

  </script>
</body>
</html>
